{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPdZnzP4LGtSVu3i+WTtf4R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MohanPatil1/Data_Science_Assignment/blob/main/Assignment_11_Text_Mining_02_Amazon_Product_Reviews.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Extract reviews of any product from ecommerce website like amazon,\n",
        "# 2. Perform emotion mining"
      ],
      "metadata": {
        "id": "RToka8hVLsSZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import string\n",
        "import spacy\n",
        "\n",
        "from matplotlib.pyplot import imread\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "2hYxj3N0Lwzy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import extracted amazon reviews Dataset (How to Extract amazon reviews - Refer Extract Amazon Reviews using Scrapy.ipynb)\n",
        "reviews=pd.read_csv('extract_reviews_test2.csv')\n",
        "reviews"
      ],
      "metadata": {
        "id": "20azZmyPL2lq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Processing"
      ],
      "metadata": {
        "id": "IUB7x16pMB-g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reviews=[comment.strip() for comment in reviews.comment] # remove both the leading and the trailing characters\n",
        "reviews=[comment for comment in reviews if comment] # removes empty strings, because they are considered in Python as False\n",
        "reviews[0:10]"
      ],
      "metadata": {
        "id": "izYmLhwhMGNP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Joining the list into one string/text\n",
        "reviews_text=' '.join(reviews)\n",
        "reviews_text"
      ],
      "metadata": {
        "id": "L-yFCfPmMAer"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Punctuations \n",
        "no_punc_text=reviews_text.translate(str.maketrans('','',string.punctuation))\n",
        "no_punc_text"
      ],
      "metadata": {
        "id": "UsyKa1UKMXmM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "5tZIHZc2McCP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import word_tokenize\n",
        "text_tokens=word_tokenize(no_punc_text)\n",
        "print(text_tokens[0:50])"
      ],
      "metadata": {
        "id": "CXce2Bm-Mnvl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(text_tokens)"
      ],
      "metadata": {
        "id": "S0xxnMR_MtGo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove stopwords\n",
        "from nltk.corpus import stopwords\n",
        "my_stop_words=stopwords.words('english')\n",
        "\n",
        "sw_list=['I','The','It','A']\n",
        "my_stop_words.extend(sw_list)\n",
        "\n",
        "no_stop_tokens=[word for word in text_tokens if not word in my_stop_words]\n",
        "print(no_stop_tokens)"
      ],
      "metadata": {
        "id": "VVZHnHkRMuIw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the data\n",
        "lower_words=[comment.lower() for comment in no_stop_tokens]\n",
        "print(lower_words)"
      ],
      "metadata": {
        "id": "9-UsqpIHMvQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Stemming (Optional)\n",
        "from nltk.stem import PorterStemmer\n",
        "ps=PorterStemmer()\n",
        "stemmed_tokens=[ps.stem(word) for word in lower_words]\n",
        "print(stemmed_tokens)"
      ],
      "metadata": {
        "id": "ql9jESvQM0Bw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lemmatization\n",
        "nlp=spacy.load('en_core_web_sm')\n",
        "doc=nlp(' '.join(lower_words))\n",
        "print(doc)"
      ],
      "metadata": {
        "id": "suwIgseoMvwV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lemmas=[token.lemma_ for token in doc]\n",
        "print(lemmas)"
      ],
      "metadata": {
        "id": "OjXXHIULNI1e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_reviews=' '.join(lemmas)\n",
        "clean_reviews"
      ],
      "metadata": {
        "id": "GCuupNVMNIkE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Extaction"
      ],
      "metadata": {
        "id": "zhrpKuM8Nonq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Using CountVectorizer"
      ],
      "metadata": {
        "id": "7qJAXCe6NwJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv=CountVectorizer()\n",
        "reviewscv=cv.fit_transform(lemmas)"
      ],
      "metadata": {
        "id": "k4_0JpoZNxzo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(cv.vocabulary_)"
      ],
      "metadata": {
        "id": "cJhxaQCVNq-f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(cv.get_feature_names()[150:300])"
      ],
      "metadata": {
        "id": "JAe1y3GyNIWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(reviewscv.toarray()[150:300])"
      ],
      "metadata": {
        "id": "x4uB6h7MNILL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(reviewscv.toarray().shape)"
      ],
      "metadata": {
        "id": "RNPcpiAJNIHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. CountVectorizer with N-grams (Bigrams & Trigrams)"
      ],
      "metadata": {
        "id": "GEkZN4S7OPHk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cv_ngram_range=CountVectorizer(analyzer='word',ngram_range=(1,3),max_features=100)\n",
        "bow_matrix_ngram=cv_ngram_range.fit_transform(lemmas)"
      ],
      "metadata": {
        "id": "GAEh1urrOQ7g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(cv_ngram_range.get_feature_names())\n",
        "print(bow_matrix_ngram.toarray())"
      ],
      "metadata": {
        "id": "bDjnOW7BNHoo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. TF-IDF Vectorizer"
      ],
      "metadata": {
        "id": "M-DUhifBOZxW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidfv_ngram_max_features=TfidfVectorizer(norm='l2',analyzer='word',ngram_range=(1,3),max_features=500)\n",
        "tfidf_matrix_ngram=tfidfv_ngram_max_features.fit_transform(lemmas)"
      ],
      "metadata": {
        "id": "wXwmsSTjObKX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tfidfv_ngram_max_features.get_feature_names())\n",
        "print(tfidf_matrix_ngram.toarray())"
      ],
      "metadata": {
        "id": "HIaqVb17OJg9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate Word Cloud"
      ],
      "metadata": {
        "id": "pa7GCLwkOlKF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to plot word cloud\n",
        "def plot_cloud(wordcloud):\n",
        "    plt.figure(figsize=(40,30))\n",
        "    plt.imshow(wordcloud)\n",
        "    plt.axis('off')\n",
        "\n",
        "# Generate word cloud\n",
        "\n",
        "STOPWORDS.add('Pron')\n",
        "wordcloud=WordCloud(width=3000,height=2000,background_color='white',max_words=100,\n",
        "                   colormap='Set2',stopwords=STOPWORDS).generate(clean_reviews)\n",
        "plot_cloud(wordcloud)"
      ],
      "metadata": {
        "id": "MoGD7ypBOmfF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Named Entity Recognition (NER)"
      ],
      "metadata": {
        "id": "j1GYHQGTOuYd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parts of speech (POS) tagging\n",
        "nlp=spacy.load('en_core_web_sm')\n",
        "\n",
        "one_block=clean_reviews\n",
        "doc_block=nlp(one_block)\n",
        "spacy.displacy.render(doc_block,style='ent',jupyter=True)"
      ],
      "metadata": {
        "id": "a7-Jib5eOvvT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for token in doc_block[100:200]:\n",
        "    print(token,token.pos_)"
      ],
      "metadata": {
        "id": "t__ohQdGOqfw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtering the nouns and verbs only\n",
        "nouns_verbs=[token.text for token in doc_block if token.pos_ in ('NOUN','VERB')]\n",
        "print(nouns_verbs[100:200])"
      ],
      "metadata": {
        "id": "Z7Tkyn5dOqUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Counting the noun & verb tokens\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv=CountVectorizer()\n",
        "\n",
        "X=cv.fit_transform(nouns_verbs)\n",
        "sum_words=X.sum(axis=0)\n",
        "\n",
        "words_freq=[(word,sum_words[0,idx]) for word,idx in cv.vocabulary_.items()]\n",
        "words_freq=sorted(words_freq,key=lambda x: x[1],reverse=True)\n",
        "\n",
        "wd_df=pd.DataFrame(words_freq)\n",
        "wd_df.columns=['word','count']\n",
        "wd_df[0:10] # viewing top ten results"
      ],
      "metadata": {
        "id": "-tSX8MvcOqJ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing results (Barchart for top 10 nouns + verbs)\n",
        "wd_df[0:10].plot.bar(x='word',figsize=(12,8),title='Top 10 nouns and verbs');"
      ],
      "metadata": {
        "id": "3-LvK0dTOp8F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Emotion Mining - Sentiment Analysis"
      ],
      "metadata": {
        "id": "XLmeXSLHQiOD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import tokenize\n",
        "sentences=tokenize.sent_tokenize(' '.join(reviews))\n",
        "sentences"
      ],
      "metadata": {
        "id": "a1LE18jWQjrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent_df=pd.DataFrame(sentences,columns=['sentence'])\n",
        "sent_df"
      ],
      "metadata": {
        "id": "oko39PtdOKIy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Emotion Lexicon - Affin\n",
        "affin=pd.read_csv('Database/Afinn.csv',sep=',',encoding='Latin-1')\n",
        "affin"
      ],
      "metadata": {
        "id": "SIPC2CYOQ1Zf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "affinity_scores=affin.set_index('word')['value'].to_dict()\n",
        "affinity_scores"
      ],
      "metadata": {
        "id": "U3DQ_seBQ1Mn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom function: score each word in a sentence in lemmatised form, but calculate the score for the whole original sentence\n",
        "nlp=spacy.load('en_core_web_sm')\n",
        "sentiment_lexicon=affinity_scores\n",
        "\n",
        "def calculate_sentiment(text:str=None):\n",
        "    sent_score=0\n",
        "    if text:\n",
        "        sentence=nlp(text)\n",
        "        for word in sentence:\n",
        "            sent_score+=sentiment_lexicon.get(word.lemma_,0)\n",
        "    return sent_score"
      ],
      "metadata": {
        "id": "2SfFeiW5Q0-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# manual testing\n",
        "calculate_sentiment(text='good service')"
      ],
      "metadata": {
        "id": "P0mDRbRSQ0vd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating sentiment value for each sentence\n",
        "sent_df['sentiment_value']=sent_df['sentence'].apply(calculate_sentiment)\n",
        "sent_df['sentiment_value']"
      ],
      "metadata": {
        "id": "23ouivSuSGr2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# how many words are there in a sentence?\n",
        "sent_df['word_count']=sent_df['sentence'].str.split().apply(len)\n",
        "sent_df['word_count']"
      ],
      "metadata": {
        "id": "cPtP438DSGak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent_df.sort_values(by='sentiment_value')"
      ],
      "metadata": {
        "id": "ZvqqYwf8SGN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sentiment score of the whole review\n",
        "sent_df['sentiment_value'].describe()"
      ],
      "metadata": {
        "id": "jrdsD22sSGBT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# negative sentiment score of the whole review\n",
        "sent_df[sent_df['sentiment_value']<=0]"
      ],
      "metadata": {
        "id": "taZPx6F0SFyu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# positive sentiment score of the whole review\n",
        "sent_df[sent_df['sentiment_value']>0]"
      ],
      "metadata": {
        "id": "uztSL9mSViZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding index cloumn\n",
        "sent_df['index']=range(0,len(sent_df))\n",
        "sent_df"
      ],
      "metadata": {
        "id": "eV4MyFVnViMi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the sentiment value for whole review\n",
        "import seaborn as sns\n",
        "plt.figure(figsize=(15,10))\n",
        "sns.distplot(sent_df['sentiment_value'])"
      ],
      "metadata": {
        "id": "vVVD_nNgVh-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the line plot for sentiment value of whole review\n",
        "plt.figure(figsize=(15,10))\n",
        "sns.lineplot(y='sentiment_value',x='index',data=sent_df)"
      ],
      "metadata": {
        "id": "syi8QKaXVhwH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}